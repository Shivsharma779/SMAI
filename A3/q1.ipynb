{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shiv_A3_q1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "h7wPix9kf0fC",
        "-yh_-VdQdyVZ",
        "UDK0lQBLeQMI",
        "rOR0R2rGdkFQ",
        "9KZ7wueydsfs",
        "YsGkNvs0davx",
        "6EYU7GBSdXxQ",
        "Q3pfq4a4dSLB",
        "FfNP-KhDdN-W",
        "u-IXH-BceE9A"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-47ZljQE9Pn"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import random_split, ConcatDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7wPix9kf0fC"
      },
      "source": [
        "# DOWNLOADING DATA AND PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbPX4FwqgJwp",
        "outputId": "0bd91a1b-22da-4a57-f3ad-5bffeefd835c"
      },
      "source": [
        "train_size = 48000\n",
        "val_size =  5000\n",
        "test_size = 12000\n",
        "batch_size=512\n",
        "random_seed = 42\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4OSLu4bFB46",
        "outputId": "c464db0a-fc10-43ad-e4fa-a85593b22e84"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "full_DS = ConcatDataset([dataset,testset])\n",
        "\n",
        "\n",
        "torch.manual_seed(random_seed);\n",
        "train_ds, testset = random_split(full_DS, [train_size, test_size])\n",
        "train_ds, val_ds = random_split(train_ds, [train_size-val_size, val_size])\n",
        "\n",
        "\n",
        "\n",
        "train_dl = torch.utils.data.DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_dl = torch.utils.data.DataLoader(val_ds, batch_size*2, num_workers=2, pin_memory=True)\n",
        "test_dl = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
        "len(train_ds), len(val_ds), len(testset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm6kJJ4ysNS4",
        "outputId": "8f59ff47-4943-4afe-ae6c-a58329e28bb2"
      },
      "source": [
        "len(train_ds), len(val_ds), len(testset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yh_-VdQdyVZ"
      },
      "source": [
        "# MODEL DEFINATIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DARd6ha8ZaDT"
      },
      "source": [
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "        \n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOgCsDcjhUmG"
      },
      "source": [
        "class part1(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.ZeroPad2d(1),\n",
        "            nn.Conv2d(3, 128, kernel_size=6),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            \n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(128*14*14, 10))\n",
        "        \n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "class part2(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.ZeroPad2d(1),\n",
        "            nn.Conv2d(3, 128, kernel_size=6),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 64 x 14 x 14\n",
        "\n",
        "            \n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(128*14*14, 10))\n",
        "        \n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "class part3(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.ZeroPad2d(1),\n",
        "            nn.Conv2d(3, 128, kernel_size=6),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 64 x 14 x 14\n",
        "\n",
        "            \n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(128*14*14, 60),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(60,10))\n",
        "        \n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "class part4(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.ZeroPad2d(1),\n",
        "            nn.Conv2d(3, 128, kernel_size=6),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Conv2d(128, 512, kernel_size=6),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 64 x 14 x 14\n",
        "\n",
        "            \n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(512*4*4, 10))\n",
        "        \n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)\n",
        "class part5(ImageClassificationBase):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.ZeroPad2d(1),\n",
        "            nn.Conv2d(3, 128, kernel_size=6),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            \n",
        "            nn.Conv2d(128, 512, kernel_size=6),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2), # output: 64 x 14 x 14\n",
        "\n",
        "            nn.Conv2d(512, 1024, kernel_size=1),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Flatten(), \n",
        "            nn.Linear(1024*2*2, 10))\n",
        "        \n",
        "\n",
        "    def forward(self, xb):\n",
        "        return self.network(xb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgIRJ0h6d4_0"
      },
      "source": [
        "# HELPER FUNCTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDK0lQBLeQMI"
      },
      "source": [
        "## DATA LOADER TO CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Cp2HJT4iJiM"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "    \n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOR0R2rGdkFQ"
      },
      "source": [
        "## HELPER FUNCTION FOR TRAINING AND EVALUATING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgK1dVNXidk3"
      },
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(question_no,epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    val_accuracy = 0\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "        if (val_accuracy < history[-1][\"val_acc\"]):\n",
        "            torch.save(model.state_dict(), question_no)\n",
        "            print(\"saving model for\", question_no)\n",
        "            val_accuracy = history[-1][\"val_acc\"]\n",
        "    return history\n",
        "def test_accuracy(model, test_loader):\n",
        "    result = evaluate(model, test_loader)    \n",
        "    return result[\"val_acc\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZ7wueydsfs"
      },
      "source": [
        "# PARAMETERS AND MOVING TO CUDA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFeo2I94ipho"
      },
      "source": [
        "num_epochs = 15\n",
        "opt_func = torch.optim.Adam\n",
        "lr = 0.001\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAltsMjheaA6"
      },
      "source": [
        "device = get_default_device()\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "val_dl = DeviceDataLoader(val_dl, device)\n",
        "test_dl = DeviceDataLoader(test_dl, device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsGkNvs0davx"
      },
      "source": [
        "#PART 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_Y-rp2tnfDW",
        "outputId": "da691365-8999-44f3-e823-c05abd85a3fc"
      },
      "source": [
        "model1 = to_device(part1(), device);\n",
        "history1 = fit(\"part1\",num_epochs, lr, model1, train_dl, val_dl, opt_func)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], train_loss: 2.0787, val_loss: 1.5533, val_acc: 0.5305\n",
            "saving model for part1\n",
            "Epoch [1], train_loss: 1.3041, val_loss: 1.4664, val_acc: 0.5712\n",
            "saving model for part1\n",
            "Epoch [2], train_loss: 1.1253, val_loss: 1.4311, val_acc: 0.5875\n",
            "saving model for part1\n",
            "Epoch [3], train_loss: 0.9803, val_loss: 1.3895, val_acc: 0.6037\n",
            "saving model for part1\n",
            "Epoch [4], train_loss: 0.8698, val_loss: 1.5447, val_acc: 0.5959\n",
            "Epoch [5], train_loss: 0.7791, val_loss: 1.4578, val_acc: 0.6036\n",
            "Epoch [6], train_loss: 0.6656, val_loss: 1.5067, val_acc: 0.6077\n",
            "saving model for part1\n",
            "Epoch [7], train_loss: 0.5968, val_loss: 1.5190, val_acc: 0.6020\n",
            "Epoch [8], train_loss: 0.5316, val_loss: 1.5397, val_acc: 0.6066\n",
            "Epoch [9], train_loss: 0.4776, val_loss: 1.5474, val_acc: 0.6182\n",
            "saving model for part1\n",
            "Epoch [10], train_loss: 0.4079, val_loss: 1.6357, val_acc: 0.6167\n",
            "Epoch [11], train_loss: 0.3802, val_loss: 1.7322, val_acc: 0.6003\n",
            "Epoch [12], train_loss: 0.3380, val_loss: 1.6813, val_acc: 0.6231\n",
            "saving model for part1\n",
            "Epoch [13], train_loss: 0.2870, val_loss: 1.7309, val_acc: 0.6198\n",
            "Epoch [14], train_loss: 0.2614, val_loss: 1.7418, val_acc: 0.6165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htTGZbhiTNyA",
        "outputId": "582f9e71-ee8e-4798-944c-384356226ccb"
      },
      "source": [
        "model1.load_state_dict(torch.load(\"part1\"))\n",
        "print(\"accuracy for part 1 = \", test_accuracy(model1,test_dl)*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy for part 1 =  62.90000081062317 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EYU7GBSdXxQ"
      },
      "source": [
        "#PART 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOI6pwRmJp_S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad66271f-b105-41cc-8148-29731ea3a3ec"
      },
      "source": [
        "model2 = to_device(part2(), device);\n",
        "history2 = fit(\"part2\",num_epochs, lr, model2, train_dl, val_dl, opt_func)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], train_loss: 1.5973, val_loss: 1.3173, val_acc: 0.5442\n",
            "saving model for part2\n",
            "Epoch [1], train_loss: 1.1977, val_loss: 1.1965, val_acc: 0.5873\n",
            "saving model for part2\n",
            "Epoch [2], train_loss: 1.0673, val_loss: 1.1125, val_acc: 0.6105\n",
            "saving model for part2\n",
            "Epoch [3], train_loss: 0.9815, val_loss: 1.0615, val_acc: 0.6315\n",
            "saving model for part2\n",
            "Epoch [4], train_loss: 0.9292, val_loss: 1.0246, val_acc: 0.6452\n",
            "saving model for part2\n",
            "Epoch [5], train_loss: 0.8770, val_loss: 1.0607, val_acc: 0.6308\n",
            "Epoch [6], train_loss: 0.8460, val_loss: 1.0013, val_acc: 0.6570\n",
            "saving model for part2\n",
            "Epoch [7], train_loss: 0.7935, val_loss: 0.9966, val_acc: 0.6559\n",
            "Epoch [8], train_loss: 0.7733, val_loss: 1.0069, val_acc: 0.6599\n",
            "saving model for part2\n",
            "Epoch [9], train_loss: 0.7349, val_loss: 0.9702, val_acc: 0.6711\n",
            "saving model for part2\n",
            "Epoch [10], train_loss: 0.7241, val_loss: 0.9998, val_acc: 0.6636\n",
            "Epoch [11], train_loss: 0.6839, val_loss: 0.9969, val_acc: 0.6638\n",
            "Epoch [12], train_loss: 0.6489, val_loss: 0.9872, val_acc: 0.6720\n",
            "saving model for part2\n",
            "Epoch [13], train_loss: 0.6441, val_loss: 1.0012, val_acc: 0.6726\n",
            "saving model for part2\n",
            "Epoch [14], train_loss: 0.6040, val_loss: 0.9894, val_acc: 0.6738\n",
            "saving model for part2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZK4Y2XrJp_T",
        "outputId": "442a49e1-39a7-413e-f8e0-2f829c12073f"
      },
      "source": [
        "model2.load_state_dict(torch.load(\"part2\"))\n",
        "print(\"accuracy for part 2 = \", test_accuracy(model2,test_dl)*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy for part 2 =  67.36666560173035 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3pfq4a4dSLB"
      },
      "source": [
        "#PART 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6DgEQq1Zjoz",
        "outputId": "83aae6c4-116e-4e1f-ebd7-00b211750565"
      },
      "source": [
        "model3 = to_device(part3(), device);\n",
        "history3 = fit(\"part3\",num_epochs, lr, model3, train_dl, val_dl, opt_func)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], train_loss: 1.8336, val_loss: 1.4594, val_acc: 0.4697\n",
            "saving model for part3\n",
            "Epoch [1], train_loss: 1.3234, val_loss: 1.2476, val_acc: 0.5462\n",
            "saving model for part3\n",
            "Epoch [2], train_loss: 1.1342, val_loss: 1.1560, val_acc: 0.5933\n",
            "saving model for part3\n",
            "Epoch [3], train_loss: 1.0237, val_loss: 1.1133, val_acc: 0.6090\n",
            "saving model for part3\n",
            "Epoch [4], train_loss: 0.9496, val_loss: 1.0794, val_acc: 0.6196\n",
            "saving model for part3\n",
            "Epoch [5], train_loss: 0.8930, val_loss: 1.0957, val_acc: 0.6246\n",
            "saving model for part3\n",
            "Epoch [6], train_loss: 0.8351, val_loss: 1.0719, val_acc: 0.6334\n",
            "saving model for part3\n",
            "Epoch [7], train_loss: 0.7761, val_loss: 1.0948, val_acc: 0.6321\n",
            "Epoch [8], train_loss: 0.7262, val_loss: 1.0828, val_acc: 0.6371\n",
            "saving model for part3\n",
            "Epoch [9], train_loss: 0.6799, val_loss: 1.0962, val_acc: 0.6355\n",
            "Epoch [10], train_loss: 0.6360, val_loss: 1.1531, val_acc: 0.6271\n",
            "Epoch [11], train_loss: 0.5839, val_loss: 1.1415, val_acc: 0.6379\n",
            "saving model for part3\n",
            "Epoch [12], train_loss: 0.5541, val_loss: 1.2103, val_acc: 0.6257\n",
            "Epoch [13], train_loss: 0.5117, val_loss: 1.2011, val_acc: 0.6362\n",
            "Epoch [14], train_loss: 0.4677, val_loss: 1.2201, val_acc: 0.6343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsYIvLZpaKHd",
        "outputId": "9cbe5fa0-bdb0-4833-f47b-223a3bf3c55a"
      },
      "source": [
        "model3.load_state_dict(torch.load(\"part3\"))\n",
        "print(\"accuracy for part 3 = \", test_accuracy(model3,test_dl)*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy for part 3 =  64.77500200271606 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfNP-KhDdN-W"
      },
      "source": [
        "#PART 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Whd9hoY5Zy62",
        "outputId": "47e380d2-95db-4715-a7a0-018efd53b7c9"
      },
      "source": [
        "model4 = to_device(part4(), device);\n",
        "history4 = fit(\"part4\",num_epochs, lr, model4, train_dl, val_dl, opt_func)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], train_loss: 1.6267, val_loss: 1.2564, val_acc: 0.5668\n",
            "saving model for part4\n",
            "Epoch [1], train_loss: 1.0251, val_loss: 1.1502, val_acc: 0.6139\n",
            "saving model for part4\n",
            "Epoch [2], train_loss: 0.7989, val_loss: 0.9627, val_acc: 0.6718\n",
            "saving model for part4\n",
            "Epoch [3], train_loss: 0.6138, val_loss: 1.0213, val_acc: 0.6729\n",
            "saving model for part4\n",
            "Epoch [4], train_loss: 0.4534, val_loss: 1.0604, val_acc: 0.6760\n",
            "saving model for part4\n",
            "Epoch [5], train_loss: 0.3159, val_loss: 1.0869, val_acc: 0.6896\n",
            "saving model for part4\n",
            "Epoch [6], train_loss: 0.2025, val_loss: 1.1289, val_acc: 0.7029\n",
            "saving model for part4\n",
            "Epoch [7], train_loss: 0.1041, val_loss: 1.1275, val_acc: 0.7168\n",
            "saving model for part4\n",
            "Epoch [8], train_loss: 0.0476, val_loss: 1.1267, val_acc: 0.7199\n",
            "saving model for part4\n",
            "Epoch [9], train_loss: 0.0191, val_loss: 1.1346, val_acc: 0.7279\n",
            "saving model for part4\n",
            "Epoch [10], train_loss: 0.0073, val_loss: 1.1659, val_acc: 0.7321\n",
            "saving model for part4\n",
            "Epoch [11], train_loss: 0.0037, val_loss: 1.1578, val_acc: 0.7334\n",
            "saving model for part4\n",
            "Epoch [12], train_loss: 0.0025, val_loss: 1.1798, val_acc: 0.7355\n",
            "saving model for part4\n",
            "Epoch [13], train_loss: 0.0020, val_loss: 1.1937, val_acc: 0.7365\n",
            "saving model for part4\n",
            "Epoch [14], train_loss: 0.0016, val_loss: 1.1975, val_acc: 0.7380\n",
            "saving model for part4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EL4eRXbaq6o",
        "outputId": "eedfdfc0-3c8c-48d5-8e44-1679ea0c61d3"
      },
      "source": [
        "model4.load_state_dict(torch.load(\"part4\"))\n",
        "print(\"accuracy for part 4 = \", test_accuracy(model4,test_dl)*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy for part 4 =  74.05833601951599 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-IXH-BceE9A"
      },
      "source": [
        "#PART 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCb3tpkqaSxC",
        "outputId": "b38a1adb-4d48-44a9-a82c-f7f04c9f28ec"
      },
      "source": [
        "model5 = to_device(part5(), device);\n",
        "history5 = fit(\"part5\",num_epochs, lr, model5, train_dl, val_dl, opt_func)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], train_loss: 1.4987, val_loss: 1.2197, val_acc: 0.5758\n",
            "saving model for part5\n",
            "Epoch [1], train_loss: 0.9667, val_loss: 1.0242, val_acc: 0.6437\n",
            "saving model for part5\n",
            "Epoch [2], train_loss: 0.7365, val_loss: 0.9517, val_acc: 0.6819\n",
            "saving model for part5\n",
            "Epoch [3], train_loss: 0.5418, val_loss: 0.9315, val_acc: 0.6846\n",
            "saving model for part5\n",
            "Epoch [4], train_loss: 0.3872, val_loss: 0.9877, val_acc: 0.6955\n",
            "saving model for part5\n",
            "Epoch [5], train_loss: 0.2437, val_loss: 0.9373, val_acc: 0.7148\n",
            "saving model for part5\n",
            "Epoch [6], train_loss: 0.1308, val_loss: 0.9902, val_acc: 0.7165\n",
            "saving model for part5\n",
            "Epoch [7], train_loss: 0.0640, val_loss: 1.0186, val_acc: 0.7240\n",
            "saving model for part5\n",
            "Epoch [8], train_loss: 0.0245, val_loss: 1.0205, val_acc: 0.7328\n",
            "saving model for part5\n",
            "Epoch [9], train_loss: 0.0070, val_loss: 1.0002, val_acc: 0.7523\n",
            "saving model for part5\n",
            "Epoch [10], train_loss: 0.0024, val_loss: 1.0176, val_acc: 0.7506\n",
            "Epoch [11], train_loss: 0.0015, val_loss: 1.0260, val_acc: 0.7517\n",
            "Epoch [12], train_loss: 0.0012, val_loss: 1.0365, val_acc: 0.7520\n",
            "Epoch [13], train_loss: 0.0010, val_loss: 1.0429, val_acc: 0.7543\n",
            "saving model for part5\n",
            "Epoch [14], train_loss: 0.0008, val_loss: 1.0525, val_acc: 0.7534\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbqywpL0avfO",
        "outputId": "1d30ca14-9968-4ddd-dcef-0461d48b76d6"
      },
      "source": [
        "model5.load_state_dict(torch.load(\"part5\"))\n",
        "print(\"accuracy for part 5 = \", test_accuracy(model5,test_dl)*100,\"%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy for part 4 =  76.43333077430725 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwXxaefwgPtg"
      },
      "source": [
        "# BEST MODEL GRAPHS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "Sdbeagt7kWPl",
        "outputId": "86f1622d-5e7e-43c6-9ab7-0e1d8f9a1192"
      },
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, '-bx')\n",
        "    plt.plot(val_losses, '-rx')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. No. of epochs');\n",
        "plot_losses(history5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLyoFgxqFFBL",
        "outputId": "6b19b65f-0b04-40b0-916b-685c9b3a0bc7"
      },
      "source": [
        "model5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "part5(\n",
              "  (network): Sequential(\n",
              "    (0): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "    (1): Conv2d(3, 128, kernel_size=(6, 6), stride=(1, 1))\n",
              "    (2): ReLU()\n",
              "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(128, 512, kernel_size=(6, 6), stride=(1, 1))\n",
              "    (7): ReLU()\n",
              "    (8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU()\n",
              "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (11): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (12): ReLU()\n",
              "    (13): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (14): ReLU()\n",
              "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (16): Flatten(start_dim=1, end_dim=-1)\n",
              "    (17): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    }
  ]
}